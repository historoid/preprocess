{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2598ab4e-4e90-43b6-86f7-1ec76bd2af60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "# config.yamlを読み込む\n",
    "with open(\"config.yaml\", \"r\", encoding=\"utf-8\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# secondary_foldersのパスを取得\n",
    "secondary_folders = config[\"secondary_folders\"]\n",
    "\n",
    "# secondary_folders 直下にあるディレクトリを収集\n",
    "patient_folders = []\n",
    "for folder in secondary_folders:\n",
    "    if os.path.exists(folder) and os.path.isdir(folder):\n",
    "        subdirs = [\n",
    "            os.path.join(folder, subdir)\n",
    "            for subdir in os.listdir(folder)\n",
    "            if os.path.isdir(os.path.join(folder, subdir))\n",
    "        ]\n",
    "        patient_folders.extend(subdirs)\n",
    "\n",
    "# データフレームに格納\n",
    "df = pd.DataFrame(patient_folders, columns=[\"patient_folder_path\"])\n",
    "\n",
    "# データフレームの表示\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58d7e5d-4af8-40a0-8e57-6ccd83589a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .CR2 ファイルを.png ファイルに変換する。\n",
    "\n",
    "import rawpy\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 患者フォルダの取得\n",
    "patient_folders = []\n",
    "for folder in secondary_folders:\n",
    "    if os.path.exists(folder) and os.path.isdir(folder):\n",
    "        subdirs = [\n",
    "            os.path.join(folder, subdir)\n",
    "            for subdir in os.listdir(folder)\n",
    "            if os.path.isdir(os.path.join(folder, subdir))\n",
    "        ]\n",
    "        patient_folders.extend(subdirs)\n",
    "\n",
    "# .cr2ファイルを抽出\n",
    "cr2_files = []\n",
    "for patient_folder in patient_folders:\n",
    "    for root, _, files in os.walk(patient_folder):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.cr2'):\n",
    "                cr2_files.append(os.path.join(root, file))\n",
    "\n",
    "# .cr2ファイルを処理して.png形式で保存\n",
    "for cr2_file in cr2_files:\n",
    "    try:\n",
    "        # rawpyで.cr2ファイルを読み込み\n",
    "        with rawpy.imread(cr2_file) as raw:\n",
    "            rgb = raw.postprocess()\n",
    "\n",
    "        # 保存先のファイルパスを生成 (.cr2 -> .png)\n",
    "        save_path = os.path.splitext(cr2_file)[0] + '.png'\n",
    "\n",
    "        # OpenCVで保存\n",
    "        cv2.imwrite(save_path, cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR))\n",
    "        print(f\"Saved: {save_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {cr2_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d34815-ced4-4a1d-9178-1762e4bdb226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .tgaファイルを抽出\n",
    "tga_files = []\n",
    "for patient_folder in patient_folders:\n",
    "    for root, _, files in os.walk(patient_folder):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.tga'):  # 大文字小文字を無視\n",
    "                tga_files.append(os.path.join(root, file))\n",
    "\n",
    "for tga_file in tga_files:\n",
    "    try:\n",
    "        # OpenCVで.tgaファイルを読み込み\n",
    "        img = cv2.imread(tga_file)\n",
    "\n",
    "        # 読み込み結果を確認\n",
    "        if img is None:\n",
    "            print(f\"Skipped (cannot read): {tga_file}\")\n",
    "            continue\n",
    "\n",
    "        # 保存先のファイルパスを生成 (.tga -> .png)\n",
    "        save_path = os.path.splitext(tga_file)[0] + '.png'\n",
    "\n",
    "        # OpenCVで保存\n",
    "        cv2.imwrite(save_path, img)\n",
    "        print(f\"Saved: {save_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {tga_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96b2a1b-9a7e-45bf-b3de-ba57954fcf91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 対象となる拡張子\n",
    "target_extensions = ('.jpg', '.jpeg', '.tif', '.tiff')\n",
    "\n",
    "# エラーが発生したファイルリスト\n",
    "error_files = []\n",
    "\n",
    "# 処理するファイルを収集\n",
    "image_files = []\n",
    "for patient_folder in patient_folders:\n",
    "    for root, _, files in os.walk(patient_folder):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(target_extensions):  # 大文字小文字を無視\n",
    "                image_files.append(os.path.join(root, file))\n",
    "\n",
    "# 画像を変換して保存\n",
    "for image_file in image_files:\n",
    "    try:\n",
    "        # OpenCVで画像を読み込み\n",
    "        img = cv2.imread(image_file)\n",
    "\n",
    "        # 読み込みエラーチェック\n",
    "        if img is None:\n",
    "            print(f\"Skipped (cannot read): {image_file}\")\n",
    "            error_files.append(image_file)\n",
    "            continue\n",
    "\n",
    "        # 画像のサイズ取得\n",
    "        height, width = img.shape[:2]\n",
    "\n",
    "        # 長辺が3000pxを超える場合は縮小\n",
    "        max_size = 3000\n",
    "        if max(height, width) > max_size:\n",
    "            scale = max_size / max(height, width)\n",
    "            new_width = int(width * scale)\n",
    "            new_height = int(height * scale)\n",
    "            img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "            print(f\"Resized: {image_file} to {new_width}x{new_height}\")\n",
    "\n",
    "        # 保存先のパスを生成 (.png形式)\n",
    "        base_name, _ = os.path.splitext(os.path.basename(image_file))\n",
    "        save_dir = os.path.dirname(image_file)\n",
    "        save_path = os.path.join(save_dir, f\"{base_name}.png\")\n",
    "\n",
    "        # 同名ファイルがある場合、連番を付与\n",
    "        counter = 1\n",
    "        while os.path.exists(save_path):\n",
    "            save_path = os.path.join(save_dir, f\"{base_name}_{counter}.png\")\n",
    "            counter += 1\n",
    "\n",
    "        # 画像を保存\n",
    "        cv2.imwrite(save_path, img)\n",
    "        print(f\"Saved: {save_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_file}: {e}\")\n",
    "        error_files.append(image_file)\n",
    "\n",
    "# エラーのあったファイルを保存\n",
    "if error_files:\n",
    "    with open(\"error_files.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for error_file in error_files:\n",
    "            f.write(f\"{error_file}\\n\")\n",
    "    print(\"Error files saved to error_files.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1288bbf7-1b7d-4ea5-ba1d-cb4b5e2e8b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "# config.yamlの読み込み\n",
    "with open(\"config.yaml\", \"r\", encoding=\"utf-8\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# secondary_foldersの取得\n",
    "secondary_folders = config[\"secondary_folders\"]\n",
    "dataset_root = config[\"dataset_root\"]\n",
    "target_extension = \".png\"\n",
    "\n",
    "# エラー記録用ログファイル\n",
    "error_log_file = \"image_processing_errors.log\"\n",
    "\n",
    "# ログファイルの初期化\n",
    "with open(error_log_file, \"w\", encoding=\"utf-8\") as log:\n",
    "    log.write(\"Image processing errors:\\n\")\n",
    "\n",
    "# 患者フォルダの確認とファイル収集\n",
    "image_data = []\n",
    "for folder in secondary_folders:\n",
    "    if not os.path.exists(folder) or not os.path.isdir(folder):\n",
    "        with open(error_log_file, \"a\", encoding=\"utf-8\") as log:\n",
    "            log.write(f\"Folder not found or is not a directory: {folder}\\n\")\n",
    "        print(f\"Warning: Folder not found or is not a directory: {folder}\")\n",
    "        continue\n",
    "\n",
    "    # 患者フォルダの収集\n",
    "    subdirs = [\n",
    "        os.path.join(folder, subdir)\n",
    "        for subdir in os.listdir(folder)\n",
    "        if os.path.isdir(os.path.join(folder, subdir))\n",
    "    ]\n",
    "\n",
    "    for subdir in subdirs:\n",
    "        try:\n",
    "            # 各患者フォルダ内の.pngファイルを収集\n",
    "            for root, _, files in os.walk(subdir):\n",
    "                for file in files:\n",
    "                    if file.lower().endswith(target_extension):\n",
    "                        relative_path = os.path.relpath(os.path.join(root, file), start=os.getcwd())\n",
    "                        image_data.append({\"dirname\": os.path.basename(subdir), \"path\": relative_path})\n",
    "        except Exception as e:\n",
    "            with open(error_log_file, \"a\", encoding=\"utf-8\") as log:\n",
    "                log.write(f\"Error processing folder {subdir}: {e}\\n\")\n",
    "            print(f\"Error processing folder {subdir}: {e}\")\n",
    "\n",
    "# データフレームの作成\n",
    "df = pd.DataFrame(image_data).drop_duplicates().reset_index(drop=True)\n",
    "df.index.name = \"index\"\n",
    "\n",
    "# 結果を.parquetに保存\n",
    "output_file = \"00_all_images.parquet\"\n",
    "df.to_parquet(output_file, index=True)\n",
    "print(f\"DataFrame saved to {output_file}\")\n",
    "\n",
    "# データセットの検証\n",
    "print(f\"Number of images processed: {len(df)}\")\n",
    "print(\"Sample data:\")\n",
    "print(df.head())\n",
    "\n",
    "# データ保存確認\n",
    "try:\n",
    "    test_df = pd.read_parquet(output_file)\n",
    "    print(f\"Parquet file read successfully. Number of rows: {len(test_df)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error reading the saved parquet file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d75777-b2e8-458b-a3e1-91d178386100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import cv2\n",
    "import polars as pl\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm  # プログレスバー用\n",
    "\n",
    "# ファイルサイズをKBに変換\n",
    "def get_file_size_kb(path):\n",
    "    try:\n",
    "        return os.path.getsize(path) / 1024\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# ファイルの作成日時と更新日時を取得\n",
    "def get_file_times(path):\n",
    "    try:\n",
    "        created_time = datetime.fromtimestamp(os.path.getctime(path))\n",
    "    except Exception:\n",
    "        created_time = None\n",
    "    try:\n",
    "        modified_time = datetime.fromtimestamp(os.path.getmtime(path))\n",
    "    except Exception:\n",
    "        modified_time = None\n",
    "    return created_time, modified_time\n",
    "\n",
    "# 画像の幅・高さを取得し、必要なら縮小\n",
    "def get_image_dimensions(path, max_size=3000):\n",
    "    try:\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            return None, None, False\n",
    "        height, width = img.shape[:2]\n",
    "        if max(height, width) > max_size:\n",
    "            scale = max_size / max(height, width)\n",
    "            width, height = int(width * scale), int(height * scale)\n",
    "            img = cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)\n",
    "            cv2.imwrite(path, img)  # 縮小後の画像を保存\n",
    "        return width, height, True\n",
    "    except Exception:\n",
    "        return None, None, False\n",
    "\n",
    "# 画像のカラーモードを取得\n",
    "def get_color_mode(path):\n",
    "    try:\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            return None\n",
    "        channels = img.shape[2] if len(img.shape) > 2 else 1\n",
    "        return 'RGB' if channels == 3 else 'RGBA' if channels == 4 else 'BW'\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# ファイルのハッシュ値を取得\n",
    "def get_file_hash(path):\n",
    "    try:\n",
    "        hasher = hashlib.sha256()\n",
    "        with open(path, 'rb') as f:\n",
    "            for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "                hasher.update(chunk)\n",
    "        return hasher.hexdigest()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# メタデータを取得する関数\n",
    "def process_image_metadata(path):\n",
    "    try:\n",
    "        readable = cv2.imread(path) is not None\n",
    "        if not readable:\n",
    "            return {\"readable\": False}\n",
    "\n",
    "        file_size = get_file_size_kb(path)\n",
    "        created_time, modified_time = get_file_times(path)\n",
    "        width, height, resized = get_image_dimensions(path)\n",
    "        color_mode = get_color_mode(path)\n",
    "        file_hash = get_file_hash(path)\n",
    "\n",
    "        return {\n",
    "            \"readable\": True,\n",
    "            \"width\": width,\n",
    "            \"height\": height,\n",
    "            \"created_time\": created_time,\n",
    "            \"modified_time\": modified_time,\n",
    "            \"color_mode\": color_mode,\n",
    "            \"file_size\": file_size,\n",
    "            \"hash\": file_hash,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"readable\": False, \"error\": str(e)}\n",
    "\n",
    "# Parquetファイルの読み込み\n",
    "df = pl.read_parquet(\"00_all_images.parquet\")\n",
    "\n",
    "# プログレスバー付きで並列処理\n",
    "metadata = []\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = {executor.submit(process_image_metadata, path): path for path in df[\"path\"]}\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing images\"):\n",
    "        metadata.append(future.result())\n",
    "\n",
    "# メタデータをPolarsのDataFrameに変換\n",
    "metadata_df = pl.DataFrame(metadata)\n",
    "\n",
    "# 元のDataFrameにメタデータを追加\n",
    "result_df = df.with_columns(metadata_df)\n",
    "\n",
    "# 結果をParquetファイルに保存\n",
    "result_df.write_parquet(\"01_add_metadata.parquet\")\n",
    "\n",
    "# 完了メッセージ\n",
    "print(\"Metadata extraction completed and saved to 01_add_metadata.parquet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b6e662a-31db-4247-a3ae-b88edf94eef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                hash dirname  \\\n",
      "0  aa026e82dc4ff273858e008faef466d7074df8fa32750d...      61   \n",
      "1  e6b3bbc1b8728b78fb12b109b50805806317b0c635d067...      61   \n",
      "2  543f55671e6eee830a9f39b4199c4bb255445d88cc36dc...      61   \n",
      "3  024d549a2895e4147a98d6d9ad530cf8bb9a3b1172fa34...      61   \n",
      "4  e7402fded8b129aca4d8810fc01a3828dd3c5077f7cfbf...      61   \n",
      "\n",
      "                created_time  exclude_same_folder  \n",
      "0 2024-11-22 20:05:13.475698                False  \n",
      "1 2024-11-22 20:05:13.295251                False  \n",
      "2 2024-11-22 20:05:13.871609                False  \n",
      "3 2024-11-22 20:05:13.666497                False  \n",
      "4 2024-11-22 20:05:14.076683                False  \n"
     ]
    }
   ],
   "source": [
    "# 同一ハッシュ値を持つ画像の除外\n",
    "# 同一患者フォルダを対象とする\n",
    "# 古い作成日時のものを残す\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Parquetファイルの読み込み\n",
    "df = pd.read_parquet(\"01_add_metadata.parquet\")\n",
    "\n",
    "# 作成日時を datetime 型に変換（必要なら）\n",
    "df[\"created_time\"] = pd.to_datetime(df[\"created_time\"], errors=\"coerce\")\n",
    "\n",
    "# サブグループごとの処理\n",
    "df[\"exclude_same_folder\"] = False  # デフォルトはFalse\n",
    "grouped = df.groupby([\"hash\", \"dirname\"])\n",
    "\n",
    "for (hash_value, dirname), group in grouped:\n",
    "    if len(group) > 1:  # 同一ハッシュ値かつ同一フォルダ内で複数ファイルがある場合\n",
    "        try:\n",
    "            # 作成日時が最も古いものを特定\n",
    "            oldest_time = group[\"created_time\"].min()\n",
    "            candidates = group[group[\"created_time\"] == oldest_time]\n",
    "            \n",
    "            if len(candidates) > 1:  # 作成日時が一致する場合\n",
    "                # ランダムに1つだけ残す\n",
    "                selected_idx = random.choice(candidates.index)\n",
    "            else:\n",
    "                # 最古の作成日時のインデックス\n",
    "                selected_idx = candidates.index[0]\n",
    "\n",
    "            # 除外対象を設定\n",
    "            df.loc[group.index.difference([selected_idx]), \"exclude_same_folder\"] = True\n",
    "\n",
    "        except Exception as e:\n",
    "            # エラーログの出力（必要なら）\n",
    "            print(f\"Error processing hash {hash_value} in folder {dirname}: {e}\")\n",
    "\n",
    "# 結果を確認\n",
    "print(df[[\"hash\", \"dirname\", \"created_time\", \"exclude_same_folder\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acf8bdc8-7f03-4392-bb6a-63954715bbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "すべてのセットの処理が完了しました！\n",
      "処理結果が 'processed_dataframe.parquet' に保存されました。\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# フォント設定（日本語対応）\n",
    "plt.rcParams[\"font.family\"] = \"Hiragino Sans\"\n",
    "\n",
    "# データフレームの準備（仮のサンプル）\n",
    "df[\"exclude_cross_folder\"] = \"include\"  # 初期値\n",
    "# exclude_same_folder 列が True の場合、exclude_cross_folder を 'exclude' に設定\n",
    "\n",
    "df.loc[df[\"exclude_same_folder\"] == True, \"exclude_cross_folder\"] = \"exclude\"\n",
    "\n",
    "# 同一ハッシュ値を持つかつ異なる患者フォルダに存在するファイルを抽出し、exclude_cross_folder を 'initial' に設定\n",
    "hash_groups = df.groupby(\"hash\")\n",
    "for hash_value, group in hash_groups:\n",
    "    # 異なる患者フォルダに分散している場合\n",
    "    if group[\"dirname\"].nunique() > 1:\n",
    "        df.loc[group.index, \"exclude_cross_folder\"] = \"initial\"\n",
    "\n",
    "# 処理対象の絞り込み\n",
    "cross_folder_candidates = df[(df[\"exclude_same_folder\"] == False) & (df[\"exclude_cross_folder\"] == \"initial\")]\n",
    "hash_groups = cross_folder_candidates.groupby(\"hash\")\n",
    "\n",
    "# 対象となるハッシュ値リスト\n",
    "remaining_hashes = hash_groups.filter(lambda g: g[\"dirname\"].nunique() > 1)[\"hash\"].unique()\n",
    "current_index = 0  # 処理中のハッシュインデックス\n",
    "\n",
    "# 残りのセット数を表示\n",
    "def update_progress():\n",
    "    print(f\"現在のセット: {current_index + 1}/{len(remaining_hashes)} (残り {len(remaining_hashes) - current_index} セット)\")\n",
    "\n",
    "# 画像表示と選択プロセス\n",
    "def process_hash(hash_value):\n",
    "    global df\n",
    "\n",
    "    # 出力をクリア\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # 進捗を表示\n",
    "    update_progress()\n",
    "\n",
    "    # 対象の画像を取得\n",
    "    candidates = cross_folder_candidates[cross_folder_candidates[\"hash\"] == hash_value]\n",
    "    unique_folders = candidates[\"dirname\"].unique()\n",
    "\n",
    "    # 描画\n",
    "    fig, axes = plt.subplots(len(unique_folders), 11, figsize=(25, 5 * len(unique_folders)))\n",
    "    if len(unique_folders) == 1:\n",
    "        axes = [axes]  # フォルダ数が1の場合に合わせる\n",
    "\n",
    "    for i, folder in enumerate(unique_folders):\n",
    "        # 候補画像を取得\n",
    "        candidate_images = candidates[candidates[\"dirname\"] == folder]\n",
    "        for j, (_, row) in enumerate(candidate_images.iterrows()):\n",
    "            img = plt.imread(row[\"path\"])\n",
    "            axes[i][j].imshow(img)\n",
    "            axes[i][j].set_title(f\"候補: {folder}\", fontsize=10)\n",
    "            axes[i][j].axis(\"off\")\n",
    "\n",
    "        # ランダム比較画像を取得（10枚に変更）\n",
    "        other_images = df[(df[\"dirname\"] == folder) & (df[\"hash\"] != hash_value)]\n",
    "        random_images = random.sample(other_images[\"path\"].tolist(), min(10, len(other_images)))\n",
    "        for j, img_path in enumerate(random_images, start=len(candidate_images)):\n",
    "            img = plt.imread(img_path)\n",
    "            axes[i][j].imshow(img)\n",
    "            axes[i][j].set_title(f\"比較: {folder}\", fontsize=8)  # 小さめのフォント\n",
    "            axes[i][j].axis(\"off\")\n",
    "\n",
    "        # 余分なサブプロットを非表示にする\n",
    "        for k in range(len(candidate_images) + len(random_images), 11):\n",
    "            axes[i][k].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ユーザー選択\n",
    "    print(\"\\n以下の選択肢から入力してください：\")\n",
    "    print(\"1. 候補画像を選択: 対象の記号 (例: a, b, ...) を入力\")\n",
    "    print(\"2. スキップ: 'skip' を入力\")\n",
    "\n",
    "    # 記号を割り当てる\n",
    "    folder_map = {chr(97 + idx): folder for idx, folder in enumerate(unique_folders)}\n",
    "    for key, folder in folder_map.items():\n",
    "        print(f\"{key}: {folder}\")\n",
    "\n",
    "    user_input = input(\"入力: \").strip()\n",
    "    if user_input == \"skip\":\n",
    "        print(\"このセットをスキップします。\")\n",
    "        return\n",
    "    elif user_input in folder_map:\n",
    "        selected_folder = folder_map[user_input]\n",
    "        # 選ばれたフォルダ以外を除外\n",
    "        exclude_indexes = candidates[candidates[\"dirname\"] != selected_folder].index\n",
    "        df.loc[exclude_indexes, \"exclude_cross_folder\"] = \"exclude\"\n",
    "        df.loc[candidates[candidates[\"dirname\"] == selected_folder].index, \"exclude_cross_folder\"] = \"include\"\n",
    "        print(f\"フォルダ '{selected_folder}' の画像を残しました。\")\n",
    "    else:\n",
    "        print(\"無効な入力です。このセットをスキップします。\")\n",
    "\n",
    "# 全体処理ループ\n",
    "while current_index < len(remaining_hashes):\n",
    "    process_hash(remaining_hashes[current_index])\n",
    "    current_index += 1\n",
    "\n",
    "# 完了メッセージ\n",
    "clear_output(wait=True)\n",
    "print(\"すべてのセットの処理が完了しました！\")\n",
    "\n",
    "# データフレームを保存\n",
    "df.to_parquet(\"02_processed_dataframe.parquet\", index=False)\n",
    "print(\"処理結果が 'processed_dataframe.parquet' に保存されました。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee191bea-1074-4cc4-9329-c09ce193f6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "集計結果:\n",
      "exclude_cross_folder\n",
      "include    15825\n",
      "exclude      216\n",
      "Name: count, dtype: int64\n",
      "\n",
      "すべての 'exclude_cross_folder' 列の値が処理済みです。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Parquet ファイルのロード\n",
    "df = pd.read_parquet(\"02_processed_dataframe.parquet\")\n",
    "\n",
    "# exclude_cross_folder 列の値の件数を集計\n",
    "summary = df[\"exclude_cross_folder\"].value_counts()\n",
    "\n",
    "# 結果を表示\n",
    "print(\"集計結果:\")\n",
    "print(summary)\n",
    "\n",
    "# 'initial' が存在するか確認\n",
    "if 'initial' in summary.index:\n",
    "    print(\"\\n'exclude_cross_folder' 列に 'initial' の値があります。処理を続行します。\")\n",
    "    \n",
    "    # 'initial' の画像を抽出\n",
    "    initial_images = df[df[\"exclude_cross_folder\"] == \"initial\"]\n",
    "    print(f\"処理対象の画像は {len(initial_images)} 件です。\")\n",
    "    \n",
    "    # 必要なら、ここに表示用のコードを追加してください\n",
    "else:\n",
    "    print(\"\\nすべての 'exclude_cross_folder' 列の値が処理済みです。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c397e5f-fb2c-4295-8cf9-beafd6e91700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "集計結果:\n",
      "too_small\n",
      "False    15901\n",
      "True       140\n",
      "Name: count, dtype: int64\n",
      "\n",
      "結果を '03_processed_dataframe_with_too_small.parquet' に保存しました。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Parquet ファイルをロード\n",
    "df = pd.read_parquet(\"02_processed_dataframe.parquet\")\n",
    "\n",
    "# too_small 列を作成\n",
    "# 条件: width または height が 256 未満の場合 True、それ以外は False\n",
    "df[\"too_small\"] = (df[\"width\"] < 256) | (df[\"height\"] < 256)\n",
    "\n",
    "# 結果を確認\n",
    "print(\"集計結果:\")\n",
    "print(df[\"too_small\"].value_counts())\n",
    "\n",
    "# 処理済みデータフレームを保存\n",
    "df.to_parquet(\"03_processed_dataframe_with_too_small.parquet\")\n",
    "print(\"\\n結果を '03_processed_dataframe_with_too_small.parquet' に保存しました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67dbb4dc-f263-49ab-9ad9-d30a41ca09b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "抽出後のデータ件数: 14895\n",
      "\n",
      "結果を 'images.parquet' に保存しました。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Parquet ファイルをロード\n",
    "df = pd.read_parquet(\"03_processed_dataframe_with_too_small.parquet\")\n",
    "\n",
    "# 指定条件に合致する行を抽出\n",
    "filtered_df = df[\n",
    "    (df[\"exclude_same_folder\"] == False) & \n",
    "    (df[\"exclude_cross_folder\"] == \"include\") & \n",
    "    (df[\"too_small\"] == False)\n",
    "]\n",
    "\n",
    "# フィルタ後のデータを保存\n",
    "filtered_df.to_parquet(\"images.parquet\")\n",
    "\n",
    "# 結果を確認\n",
    "print(\"抽出後のデータ件数:\", len(filtered_df))\n",
    "print(\"\\n結果を 'images.parquet' に保存しました。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce76b86-187d-431a-a893-992bfb353a42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(ml_env)",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
