{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa171528-9da2-466e-8d06-9e51e68629d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from myfunctions import util as mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd694fe8-bef1-43c1-8688-1970b0b1a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # データフレームの整理\n",
    "\n",
    "# parquet_path = \"../03_Collect_Images/images.parquet\"\n",
    "# df = pl.read_parquet(parquet_path)\n",
    "\n",
    "# # 条件に基づいてデータをフィルタリング\n",
    "# filtered_df = (\n",
    "#     df.filter(pl.col(\"readable\") == True)  # readable列がTrue\n",
    "#       .filter(pl.col(\"width\") >= 256)      # widthが256以上\n",
    "#       .filter(pl.col(\"height\") >= 256)     # heightが256以上\n",
    "#       .filter(pl.col(\"color_mode\").is_in([\"RGB\", \"RGBA\"]))  # color_modeがRGBまたはRGBA\n",
    "#       .filter(pl.col(\"exclude_same_folder\") == False)  # exclude_same_folderがFalse\n",
    "#       .filter(pl.col(\"exclude_cross_folder\") == \"include\")  # exclude_cross_folderが'include'\n",
    "#       .filter(pl.col(\"too_small\") == False)  # too_smallがFalse\n",
    "#       .filter(~pl.col(\"path\").str.contains(\"chart\"))  # path列に'chart'を含まない\n",
    "# )\n",
    "\n",
    "# # 不要な列を削除\n",
    "# filtered_df = filtered_df.drop([\"readable\", \"exclude_same_folder\", \"exclude_cross_folder\", \"too_small\", \"hash\", \"__index_level_0__\"])\n",
    "\n",
    "# # 列の順序変更: indexを0列目に移動\n",
    "# columns = [\"index\"] + [col for col in filtered_df.columns if col != \"index\"]\n",
    "# filtered_df = filtered_df.select(columns)\n",
    "\n",
    "# # 保存\n",
    "# output_parquet_path = \"./images.parquet\"\n",
    "# filtered_df.write_parquet(output_parquet_path)\n",
    "\n",
    "# # 結果を確認\n",
    "# filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bf74754-6955-4cdf-8153-0bb92026b8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ランダムに100行選択\n",
    "# df = pl.read_parquet(\"./images.parquet\")\n",
    "\n",
    "# # 画像の色ヒストグラムを並列処理で計算\n",
    "# def process_row_for_color_histogram(row):\n",
    "#     \"\"\"\n",
    "#     各画像について色ヒストグラムを計算する。\n",
    "\n",
    "#     Args:\n",
    "#         row: データフレームの1行（辞書形式）。\n",
    "\n",
    "#     Returns:\n",
    "#         色ヒストグラム（NumPy配列）。\n",
    "#     \"\"\"\n",
    "#     # 画像を読み込む（OpenCV形式）\n",
    "#     image = mi.load_image(row[\"path\"], library=\"opencv\")\n",
    "#     if image is None:\n",
    "#         return None\n",
    "\n",
    "#     # 画像を前処理（明るさ補正とコントラスト強調を統合）\n",
    "#     preprocessed_image = mi.preprocess_image(image, gamma=1.5, clip_limit=2.0, tile_grid_size=(8, 8))\n",
    "\n",
    "#     # チャンネル数を確認し、必要に応じて補正\n",
    "#     if preprocessed_image.ndim == 2:  # グレースケールの場合\n",
    "#         preprocessed_image = cv2.cvtColor(preprocessed_image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "#     # 画像をリサイズ\n",
    "#     resized_image = mi.resize_image(preprocessed_image, max_length=128)\n",
    "#     if resized_image is None:\n",
    "#         return None\n",
    "\n",
    "#     # チャンネル数を再確認（念のため）\n",
    "#     if resized_image.ndim != 3 or resized_image.shape[2] != 3:\n",
    "#         print(f\"Warning: Unexpected channel configuration for image at path: {row['path']}\")\n",
    "#         return None\n",
    "\n",
    "#     # 色ヒストグラムを計算\n",
    "#     return mi.calculate_color_histogram(resized_image)\n",
    "\n",
    "\n",
    "# with ThreadPoolExecutor() as executor:\n",
    "#     # プログレスバーを設定\n",
    "#     results = list(tqdm(executor.map(process_row_for_color_histogram, df.to_dicts()), total=len(df)))\n",
    "\n",
    "# # 結果をDataFrameに追加\n",
    "# df = df.with_columns(pl.Series(\"color_histogram\", results))\n",
    "\n",
    "# # PCAで次元削減\n",
    "# pca_features = mi.pca_reduction(df[\"color_histogram\"].to_list(), n_components=32)\n",
    "# df = df.with_columns(pl.Series(\"color_histogram_pca\", pca_features.tolist()))\n",
    "\n",
    "# # 標準化\n",
    "# normalized_features = mi.normalize_zscore(df[\"color_histogram_pca\"].to_list())\n",
    "# df = df.with_columns(pl.Series(\"color_histogram_std\", normalized_features.tolist()))\n",
    "\n",
    "# # Noneやゼロ埋めが含まれているか確認\n",
    "# none_count = mi.count_none_in_column(df, \"color_histogram_std\")\n",
    "# print(f\"None values in color_histogram: {none_count}\")\n",
    "\n",
    "# zero_count = mi.count_zeros_in_column(df, \"color_histogram_std\")\n",
    "# print(f\"Zero values in color_histogram: {zero_count}\")\n",
    "\n",
    "# # 次元が揃っているか確認\n",
    "# mi.check_dimensions(df, \"color_histogram_std\")\n",
    "\n",
    "# # 確認\n",
    "# print(df.head())\n",
    "\n",
    "# # 保存\n",
    "# output_parquet_path = \"./temp.parquet\"\n",
    "# df.write_parquet(output_parquet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c18ce95-a278-4c9d-8bb6-f8ff62e59e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # データフレームの読み込み\n",
    "# df = pl.read_parquet(\"./temp.parquet\")\n",
    "\n",
    "# # Perceptual Hashを計算する関数\n",
    "# def process_row_for_phash(row):\n",
    "#     \"\"\"\n",
    "#     各画像についてPerceptual Hashを計算する。\n",
    "\n",
    "#     Args:\n",
    "#         row: データフレームの1行（辞書形式）。\n",
    "\n",
    "#     Returns:\n",
    "#         Perceptual Hash（文字列）。\n",
    "#     \"\"\"\n",
    "#     # 画像を読み込む（Pillow形式）\n",
    "#     image = mi.load_image(row[\"path\"], library=\"pillow\")\n",
    "#     if image is None:\n",
    "#         return None\n",
    "\n",
    "#     # 画像を前処理（明るさ補正とコントラスト強調を統合）\n",
    "#     preprocessed_image = mi.preprocess_image(image, gamma=1.5, clip_limit=2.0, tile_grid_size=(8, 8))\n",
    "\n",
    "#     # NumPy配列形式の場合はPillow形式に変換\n",
    "#     if isinstance(preprocessed_image, np.ndarray):\n",
    "#         preprocessed_image = Image.fromarray(preprocessed_image)\n",
    "\n",
    "#     # PIL.Imageのグレースケール画像をRGB形式に変換\n",
    "#     if preprocessed_image.mode != \"RGB\":\n",
    "#         preprocessed_image = preprocessed_image.convert(\"RGB\")\n",
    "\n",
    "#     # 画像をリサイズ\n",
    "#     resized_image = mi.resize_image(preprocessed_image, max_length=128)\n",
    "#     if resized_image is None:\n",
    "#         return None\n",
    "\n",
    "#     # Perceptual Hashを計算\n",
    "#     return mi.calculate_perceptual_hash(resized_image)\n",
    "\n",
    "# # 並列処理でPerceptual Hashを計算\n",
    "# with ThreadPoolExecutor() as executor:\n",
    "#     print(\"Calculating Perceptual Hashes...\")\n",
    "#     phash_results = list(tqdm(executor.map(process_row_for_phash, df.to_dicts()), total=len(df)))\n",
    "\n",
    "# # 結果をDataFrameに追加\n",
    "# df = df.with_columns(pl.Series(\"perceptual_hash\", phash_results))\n",
    "\n",
    "# # Noneの件数を確認\n",
    "# none_count = mi.count_none_in_column(df, \"perceptual_hash\")\n",
    "# print(f\"None values in perceptual_hash: {none_count}\")\n",
    "\n",
    "# # 結果を表示\n",
    "# print(df.head())\n",
    "\n",
    "# # 保存\n",
    "# output_parquet_path = \"./temp.parquet\"\n",
    "# df.write_parquet(output_parquet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdceec8f-6b86-4b12-929f-b25a035eaa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ORB特徴量\n",
    "\n",
    "# # Parquetデータを読み込む\n",
    "# df = pl.read_parquet(\"./temp.parquet\")\n",
    "\n",
    "# # 1. ランダムに100例選択\n",
    "# image_paths = df[\"path\"].sample(1000).to_list()\n",
    "\n",
    "# # 2. コードブックを生成\n",
    "# print(\"Creating codebook...\")\n",
    "# codebook = mi.create_codebook_orb(image_paths, n_clusters=128, max_length=128)  # リサイズを適用\n",
    "\n",
    "# # 3. ORB特徴量を固定次元化\n",
    "# def process_row_for_orb(row, codebook):\n",
    "#     \"\"\"\n",
    "#     各画像について、固定次元のORBヒストグラムを計算する。\n",
    "\n",
    "#     Args:\n",
    "#         row: データフレームの1行（辞書形式）。\n",
    "#         codebook: ORB記述子のクラスタ中心（コードブック）。\n",
    "\n",
    "#     Returns:\n",
    "#         固定次元のORBヒストグラム（NumPy配列）。\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         # 画像を読み込む\n",
    "#         image = mi.load_image(row[\"path\"], library=\"opencv\")\n",
    "#         if image is None:\n",
    "#             return np.zeros(len(codebook))  # ゼロベクトルを返す\n",
    "\n",
    "#         # 画像を前処理（明るさ補正とコントラスト強調を統合）\n",
    "#         preprocessed_image = mi.preprocess_image(image, gamma=1.5, clip_limit=2.0, tile_grid_size=(8, 8))\n",
    "\n",
    "#         # 画像をリサイズ\n",
    "#         resized_image = mi.resize_image(preprocessed_image, max_length=128)\n",
    "#         if resized_image is None:\n",
    "#             return np.zeros(len(codebook))  # リサイズ失敗時もゼロベクトルを返す\n",
    "\n",
    "#         # ORB記述子を抽出\n",
    "#         descriptors = mi.extract_orb_descriptors(resized_image)\n",
    "#         if descriptors is None:\n",
    "#             return np.zeros(len(codebook))  # 記述子が取得できなかった場合もゼロベクトルを返す\n",
    "\n",
    "#         # 固定次元のヒストグラムを計算\n",
    "#         return mi.compute_histogram_from_descriptors(descriptors, codebook)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing row with path {row['path']}: {e}\")\n",
    "#         return np.zeros(len(codebook))  # エラー時もゼロベクトルを返す\n",
    "\n",
    "\n",
    "# # 並列処理でORBヒストグラムを計算\n",
    "# with ThreadPoolExecutor() as executor:\n",
    "#     print(\"Calculating ORB histograms with resized images...\")\n",
    "#     orb_results = list(tqdm(\n",
    "#         executor.map(lambda row: process_row_for_orb(row, codebook), df.to_dicts()),\n",
    "#         total=len(df)\n",
    "#     ))\n",
    "\n",
    "# # ORBヒストグラム列を追加\n",
    "# df = df.with_columns(pl.Series(\"orb_histogram\", orb_results))\n",
    "\n",
    "# # 4. UMAPによる次元削減\n",
    "# print(\"Applying UMAP for dimensionality reduction...\")\n",
    "# orb_histograms = df[\"orb_histogram\"].to_list()  # リスト形式で取得\n",
    "# orb_histogram_umap = mi.umap_reduction(orb_histograms, n_components=32)\n",
    "\n",
    "# # 次元削減結果を追加\n",
    "# df = df.with_columns(pl.Series(\"orb_histogram_umap\", orb_histogram_umap.tolist()))\n",
    "\n",
    "# # 標準化\n",
    "# normalized_features = mi.normalize_zscore(df[\"orb_histogram_umap\"].to_list())\n",
    "# df = df.with_columns(pl.Series(\"orb_histogram_std\", normalized_features.tolist()))\n",
    "\n",
    "# # 5. 列にNoneが含まれていないか確認\n",
    "# none_count = mi.count_none_in_column(df, \"orb_histogram_std\")\n",
    "# print(f\"None values in 'orb_histogram_std': {none_count}\")\n",
    "\n",
    "# # 6. 次元が一致しているか確認\n",
    "# mi.check_dimensions(df, \"orb_histogram_std\")\n",
    "\n",
    "# # 7. 結果を確認\n",
    "# print(df.head())\n",
    "\n",
    "# # 8. 保存\n",
    "# df.write_parquet(output_parquet_path)\n",
    "# print(f\"Processed DataFrame saved to {output_parquet_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d05494bd-b292-448a-8755-5751abca9ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pl.read_parquet(\"./temp.parquet\")\n",
    "\n",
    "# # エッジ特徴量を並列処理で計算\n",
    "# def process_row_for_edge_histogram(row):\n",
    "#     \"\"\"\n",
    "#     各画像についてエッジヒストグラムを計算する。\n",
    "\n",
    "#     Args:\n",
    "#         row: データフレームの1行（辞書形式）。\n",
    "\n",
    "#     Returns:\n",
    "#         エッジヒストグラム（リスト）。\n",
    "#     \"\"\"\n",
    "#     # 画像を読み込む（OpenCV形式）\n",
    "#     image = mi.load_image(row[\"path\"], library=\"opencv\")\n",
    "#     if image is None:\n",
    "#         return None\n",
    "\n",
    "#     # 画像を前処理（明るさ補正とコントラスト強調を統合）\n",
    "#     preprocessed_image = mi.preprocess_image(image, gamma=1.5, clip_limit=2.0, tile_grid_size=(8, 8))\n",
    "\n",
    "#     # 画像をリサイズ\n",
    "#     resized_image = mi.resize_image(preprocessed_image, max_length=128)\n",
    "#     if resized_image is None:\n",
    "#         return None\n",
    "\n",
    "#     # エッジを検出\n",
    "#     edges = mi.detect_edges(resized_image, method=\"canny\", threshold1=50, threshold2=150)\n",
    "#     if edges is None:\n",
    "#         return None\n",
    "\n",
    "#     # エッジヒストグラムを計算\n",
    "#     return mi.calculate_edge_histogram(edges, bins=128, range=(0, 256))\n",
    "\n",
    "# with ThreadPoolExecutor() as executor:\n",
    "#     print(\"Calculating edge histograms...\")\n",
    "#     edge_results = list(tqdm(executor.map(process_row_for_edge_histogram, df.to_dicts()), total=len(df)))\n",
    "\n",
    "# # エッジヒストグラム列を追加\n",
    "# df = df.with_columns(pl.Series(\"edge_histogram\", edge_results))\n",
    "\n",
    "# # PCAで次元削減\n",
    "# pca_features = mi.pca_reduction(df[\"edge_histogram\"].to_list(), n_components=32)\n",
    "# df = df.with_columns(pl.Series(\"edge_histogram_pca\", pca_features.tolist()))\n",
    "\n",
    "# # 標準化\n",
    "# normalized_features = mi.normalize_zscore(df[\"edge_histogram_pca\"].to_list())\n",
    "# df = df.with_columns(pl.Series(\"edge_histogram_std\", normalized_features.tolist()))\n",
    "\n",
    "# # Noneや次元の確認\n",
    "# none_count = mi.count_none_in_column(df, \"edge_histogram_std\")\n",
    "# print(f\"None values in edge_histogram_std: {none_count}\")\n",
    "# mi.check_dimensions(df, \"edge_histogram_std\")\n",
    "\n",
    "# # 結果を保存\n",
    "# output_parquet_path = \"./temp.parquet\"\n",
    "# df.write_parquet(output_parquet_path)\n",
    "# print(f\"Processed DataFrame saved to {output_parquet_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55822c99-a7a2-434c-8480-ef79b3c51cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # データフレームの読み込み\n",
    "# df = pl.read_parquet(\"./temp.parquet\")\n",
    "\n",
    "# # 平均輝度と分散輝度を並列処理で計算\n",
    "# def process_row_for_brightness(row):\n",
    "#     \"\"\"\n",
    "#     各画像について平均輝度と分散輝度を計算する。\n",
    "\n",
    "#     Args:\n",
    "#         row: データフレームの1行（辞書形式）。\n",
    "\n",
    "#     Returns:\n",
    "#         平均輝度と分散輝度（タプル）。\n",
    "#     \"\"\"\n",
    "#     # 画像を読み込む（OpenCV形式）\n",
    "#     image = mi.load_image(row[\"path\"], library=\"opencv\")\n",
    "#     if image is None:\n",
    "#         return None, None\n",
    "\n",
    "#     # 画像を前処理（明るさ補正とコントラスト強調を統合）\n",
    "#     preprocessed_image = mi.preprocess_image(image, gamma=1.5, clip_limit=2.0, tile_grid_size=(8, 8))\n",
    "\n",
    "#     # 画像をリサイズ\n",
    "#     resized_image = mi.resize_image(preprocessed_image, max_length=128)\n",
    "#     if resized_image is None:\n",
    "#         return None, None\n",
    "\n",
    "#     # 平均輝度と分散輝度を計算\n",
    "#     mean_brightness, variance_brightness = mi.calculate_brightness_stats(resized_image)\n",
    "#     return mean_brightness, variance_brightness\n",
    "\n",
    "\n",
    "# # 並列処理で平均輝度と分散輝度を計算\n",
    "# with ThreadPoolExecutor() as executor:\n",
    "#     print(\"Calculating brightness features...\")\n",
    "#     brightness_results = list(tqdm(executor.map(process_row_for_brightness, df.to_dicts()), total=len(df)))\n",
    "\n",
    "# # 平均輝度と分散輝度を個別に取得\n",
    "# mean_brightness_list, variance_brightness_list = zip(*brightness_results)\n",
    "\n",
    "# # データフレームに列を追加\n",
    "# df = df.with_columns(\n",
    "#     pl.Series(\"mean_brightness\", mean_brightness_list),\n",
    "#     pl.Series(\"variance_brightness\", variance_brightness_list),\n",
    "# )\n",
    "\n",
    "# # Noneが含まれているか確認\n",
    "# none_count_mean = mi.count_none_in_column(df, \"mean_brightness\")\n",
    "# none_count_variance = mi.count_none_in_column(df, \"variance_brightness\")\n",
    "# print(f\"None values in mean_brightness: {none_count_mean}\")\n",
    "# print(f\"None values in variance_brightness: {none_count_variance}\")\n",
    "\n",
    "# # Zスコア正規化を適用（variance_brightness のみ）\n",
    "# print(\"Normalizing variance_brightness using Z-score normalization...\")\n",
    "# variance_brightness_normalized = mi.normalize_zscore(df[\"variance_brightness\"].to_list())\n",
    "# df = df.with_columns(pl.Series(\"variance_brightness_std\", variance_brightness_normalized.tolist()))\n",
    "\n",
    "# # Noneが含まれているか確認\n",
    "# none_count_std = mi.count_none_in_column(df, \"variance_brightness_std\")\n",
    "# print(f\"None values in variance_brightness_std: {none_count_std}\")\n",
    "\n",
    "# # 結果を確認\n",
    "# print(df.head())\n",
    "\n",
    "# # 保存\n",
    "# output_parquet_path = \"./temp.parquet\"\n",
    "# df.write_parquet(output_parquet_path)\n",
    "# print(f\"Processed DataFrame saved to {output_parquet_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1993add6-ed3a-4923-a393-2a40cb2291fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parquetデータを読み込む\n",
    "# df = pl.read_parquet(\"./temp.parquet\")\n",
    "\n",
    "# # GLCM特徴量を並列処理で計算\n",
    "# def process_row_for_glcm(row):\n",
    "#     \"\"\"\n",
    "#     各画像についてGLCM特徴量を計算する。\n",
    "\n",
    "#     Args:\n",
    "#         row: データフレームの1行（辞書形式）。\n",
    "\n",
    "#     Returns:\n",
    "#         GLCM特徴量（NumPy配列）。\n",
    "#     \"\"\"\n",
    "#     # 画像を読み込む（OpenCV形式）\n",
    "#     image = mi.load_image(row[\"path\"], library=\"opencv\")\n",
    "#     if image is None:\n",
    "#         return None\n",
    "\n",
    "#     # 画像を前処理（明るさ補正とコントラスト強調を統合）\n",
    "#     preprocessed_image = mi.preprocess_image(image, gamma=1.5, clip_limit=2.0, tile_grid_size=(8, 8))\n",
    "\n",
    "#     # グレースケール変換（必要な場合のみ）\n",
    "#     if preprocessed_image.ndim == 3:  # カラー画像の場合\n",
    "#         gray_image = cv2.cvtColor(preprocessed_image, cv2.COLOR_BGR2GRAY)\n",
    "#     else:  # すでにグレースケールの場合\n",
    "#         gray_image = preprocessed_image\n",
    "\n",
    "#     # 画像をリサイズ\n",
    "#     resized_image = mi.resize_image(gray_image, max_length=128)\n",
    "#     if resized_image is None:\n",
    "#         return None\n",
    "\n",
    "#     # GLCM特徴量を計算\n",
    "#     return mi.calculate_glcm_features(resized_image)\n",
    "\n",
    "# # 並列処理でGLCM特徴量を計算\n",
    "# with ThreadPoolExecutor() as executor:\n",
    "#     print(\"Calculating GLCM features...\")\n",
    "#     glcm_results = list(tqdm(executor.map(process_row_for_glcm, df.to_dicts()), total=len(df)))\n",
    "\n",
    "# # データフレームに列を追加\n",
    "# df = df.with_columns(pl.Series(\"glcm_features\", glcm_results))\n",
    "\n",
    "# # Noneが含まれているか確認\n",
    "# none_count = mi.count_none_in_column(df, \"glcm_features\")\n",
    "# print(f\"None values in glcm_features: {none_count}\")\n",
    "\n",
    "# # 次元が一致しているか確認\n",
    "# mi.check_dimensions(df, \"glcm_features\")\n",
    "\n",
    "# # GLCM特徴量をZスコア正規化\n",
    "# print(\"Normalizing GLCM features using Z-score normalization...\")\n",
    "# glcm_normalized = mi.normalize_zscore(df[\"glcm_features\"].to_list())\n",
    "# df = df.with_columns(pl.Series(\"glcm_features_std\", glcm_normalized.tolist()))\n",
    "\n",
    "# # 正規化後の列にNoneが含まれていないか確認\n",
    "# none_count_std = mi.count_none_in_column(df, \"glcm_features_std\")\n",
    "# print(f\"None values in glcm_features_std: {none_count_std}\")\n",
    "\n",
    "# # 結果を確認\n",
    "# print(df.head())\n",
    "\n",
    "# # 保存\n",
    "# output_parquet_path = \"./temp_with_glcm.parquet\"\n",
    "# df.write_parquet(output_parquet_path)\n",
    "# print(f\"Processed DataFrame saved to {output_parquet_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd955a4c-2dcc-41ec-8e68-cc62e28944cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # データフレームの読み込み\n",
    "# df = pl.read_parquet(\"./temp.parquet\")\n",
    "\n",
    "# # LBP特徴量を計算\n",
    "# def process_row_for_lbp(row, radius=1, n_points=8, method=\"uniform\", max_length=128):\n",
    "#     \"\"\"\n",
    "#     各画像についてLBP特徴量を計算する。\n",
    "\n",
    "#     Args:\n",
    "#         row: データフレームの1行（辞書形式）。\n",
    "#         radius: LBPの半径。\n",
    "#         n_points: LBPの近隣点数。\n",
    "#         method: LBPの計算方法。\n",
    "#         max_length: リサイズ時の画像の長辺の最大ピクセル数。\n",
    "\n",
    "#     Returns:\n",
    "#         LBP特徴量（NumPy配列）。\n",
    "#     \"\"\"\n",
    "#     # 画像を読み込む（OpenCV形式）\n",
    "#     image = mi.load_image(row[\"path\"], library=\"opencv\")\n",
    "#     if image is None:\n",
    "#         return np.zeros(59)  # 59次元のゼロベクトルを返す\n",
    "\n",
    "#     # 画像を前処理（明るさ補正とコントラスト強調を統合）\n",
    "#     preprocessed_image = mi.preprocess_image(image, gamma=1.5, clip_limit=2.0, tile_grid_size=(8, 8))\n",
    "\n",
    "#     # グレースケール変換が必要か確認\n",
    "#     if preprocessed_image.ndim == 3:  # カラーチャンネルがある場合\n",
    "#         gray_image = cv2.cvtColor(preprocessed_image, cv2.COLOR_BGR2GRAY)\n",
    "#     else:\n",
    "#         gray_image = preprocessed_image\n",
    "\n",
    "#     # 画像をリサイズ\n",
    "#     resized_image = mi.resize_image(gray_image, max_length=max_length)\n",
    "#     if resized_image is None:\n",
    "#         return np.zeros(59)  # リサイズ失敗時もゼロベクトルを返す\n",
    "\n",
    "#     # LBP特徴量を計算\n",
    "#     return mi.calculate_lbp_histogram(resized_image, radius=radius, n_points=n_points, method=method)\n",
    "\n",
    "# # 並列処理でLBP特徴量を計算\n",
    "# with ThreadPoolExecutor() as executor:\n",
    "#     print(\"Calculating LBP features...\")\n",
    "#     lbp_results = list(tqdm(\n",
    "#         executor.map(lambda row: process_row_for_lbp(row), df.to_dicts()),\n",
    "#         total=len(df)\n",
    "#     ))\n",
    "\n",
    "# # データフレームに列を追加\n",
    "# df = df.with_columns(pl.Series(\"lbp_features\", lbp_results))\n",
    "\n",
    "# # 次元削減（UMAPで32次元へ）\n",
    "# print(\"Reducing LBP features using UMAP...\")\n",
    "# lbp_features_umap = mi.umap_reduction(lbp_features_normalized, n_components=32)\n",
    "# df = df.with_columns(pl.Series(\"lbp_features_umap\", lbp_features_umap.tolist()))\n",
    "\n",
    "# # Zスコア正規化を適用\n",
    "# print(\"Normalizing LBP features using Z-score normalization...\")\n",
    "# lbp_features_normalized = mi.normalize_zscore(df[\"lbp_features_umap\"].to_list())\n",
    "# df = df.with_columns(pl.Series(\"lbp_features_std\", lbp_features_normalized.tolist()))\n",
    "\n",
    "# # Noneが含まれているか確認\n",
    "# none_count = mi.count_none_in_column(df, \"lbp_features_std\")\n",
    "# print(f\"None values in lbp_features_umap: {none_count}\")\n",
    "\n",
    "# # 次元が一致しているか確認\n",
    "# mi.check_dimensions(df, \"lbp_features_std\")\n",
    "\n",
    "# # データフレームの確認\n",
    "# print(df.head())\n",
    "\n",
    "# # 保存\n",
    "# output_parquet_path = \"./processed_with_lbp.parquet\"\n",
    "# df.write_parquet(output_parquet_path)\n",
    "# print(f\"Processed DataFrame saved to {output_parquet_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "800f8a4c-8561-4db2-ab23-d2cc8bebc7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # データフレームの読み込み\n",
    "# df = pl.read_parquet(\"./temp.parquet\")\n",
    "\n",
    "# # Gaborフィルタ特徴量を計算する関数\n",
    "# def process_row_for_gabor(row, frequencies, thetas, max_length=128):\n",
    "#     \"\"\"\n",
    "#     各画像についてGaborフィルタ特徴量を計算する。\n",
    "\n",
    "#     Args:\n",
    "#         row: データフレームの1行（辞書形式）。\n",
    "#         frequencies: List of frequencies for the Gabor filters.\n",
    "#         thetas: List of orientations (angles in radians) for the Gabor filters.\n",
    "#         max_length: リサイズ時の画像の長辺の最大ピクセル数。\n",
    "\n",
    "#     Returns:\n",
    "#         Gaborフィルタ特徴量（NumPy配列）。\n",
    "#     \"\"\"\n",
    "#     # 画像を読み込む（OpenCV形式）\n",
    "#     image = mi.load_image(row[\"path\"], library=\"opencv\")\n",
    "#     if image is None:\n",
    "#         return None\n",
    "\n",
    "#     # 画像を前処理（明るさ補正とコントラスト強調を統合）\n",
    "#     preprocessed_image = mi.preprocess_image(image, gamma=1.5, clip_limit=2.0, tile_grid_size=(8, 8))\n",
    "\n",
    "#     # グレースケール変換\n",
    "#     if preprocessed_image.ndim == 3:  # カラー画像の場合\n",
    "#         gray_image = cv2.cvtColor(preprocessed_image, cv2.COLOR_BGR2GRAY)\n",
    "#     else:\n",
    "#         gray_image = preprocessed_image\n",
    "\n",
    "#     # 画像をリサイズ\n",
    "#     resized_image = mi.resize_image(gray_image, max_length=max_length)\n",
    "#     if resized_image is None:\n",
    "#         return None\n",
    "\n",
    "#     # Gaborフィルタ特徴量を計算\n",
    "#     return mi.apply_gabor_filters(resized_image, frequencies=frequencies, thetas=thetas)\n",
    "\n",
    "# # パラメータ設定\n",
    "# frequencies = [0.1, 0.2, 0.3, 0.4, 0.5]  # Example frequencies\n",
    "# thetas = [0, np.pi / 4, np.pi / 2, 3 * np.pi / 4]  # Example orientations\n",
    "\n",
    "# # 並列処理でGaborフィルタ特徴量を計算\n",
    "# with ThreadPoolExecutor() as executor:\n",
    "#     print(\"Calculating Gabor features...\")\n",
    "#     gabor_results = list(tqdm(\n",
    "#         executor.map(lambda row: process_row_for_gabor(row, frequencies, thetas), df.to_dicts()),\n",
    "#         total=len(df)\n",
    "#     ))\n",
    "\n",
    "# # Gaborフィルタ特徴量列を追加\n",
    "# df = df.with_columns(pl.Series(\"gabor_features\", gabor_results))\n",
    "\n",
    "# # Noneが含まれているか確認\n",
    "# none_count = mi.count_none_in_column(df, \"gabor_features\")\n",
    "# print(f\"None values in gabor_features: {none_count}\")\n",
    "\n",
    "# # 次元が一致しているか確認\n",
    "# mi.check_dimensions(df, \"gabor_features\")\n",
    "\n",
    "# # Gabor特徴量をZスコア正規化\n",
    "# print(\"Normalizing Gabor features using Z-score normalization...\")\n",
    "# gabor_features_normalized = mi.normalize_zscore(df[\"gabor_features\"].to_list())\n",
    "# df = df.with_columns(pl.Series(\"gabor_features_std\", gabor_features_normalized.tolist()))\n",
    "\n",
    "# # Noneが含まれているか確認\n",
    "# none_count_std = mi.count_none_in_column(df, \"gabor_features_std\")\n",
    "# print(f\"None values in gabor_features_std: {none_count_std}\")\n",
    "\n",
    "# # 結果を確認\n",
    "# print(df.head())\n",
    "\n",
    "# # 保存\n",
    "# output_parquet_path = \"./temp_with_gabor.parquet\"\n",
    "# df.write_parquet(output_parquet_path)\n",
    "# print(f\"Processed DataFrame saved to {output_parquet_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08e8e762-445d-4a64-a56d-f950668c714f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # データフレームを読み込む\n",
    "# df = pl.read_parquet(\"./temp.parquet\")\n",
    "\n",
    "# # HOG特徴量を計算する関数\n",
    "# def process_row_for_hog(row, max_length=128, target_length=5000):\n",
    "#     \"\"\"\n",
    "#     各画像についてHOG特徴量を計算し、次元を揃える。\n",
    "\n",
    "#     Args:\n",
    "#         row: データフレームの1行（辞書形式）。\n",
    "#         max_length: リサイズ時の画像の長辺の最大ピクセル数。\n",
    "#         target_length: HOG特徴量のターゲット次元数。\n",
    "\n",
    "#     Returns:\n",
    "#         次元を揃えたHOG特徴量（NumPy配列）。\n",
    "#     \"\"\"\n",
    "#     # 画像を読み込む\n",
    "#     image = mi.load_image(row[\"path\"], library=\"opencv\")\n",
    "#     if image is None:\n",
    "#         return np.zeros(target_length)  # ゼロベクトルを返す\n",
    "\n",
    "#     # 画像を前処理\n",
    "#     preprocessed_image = mi.preprocess_image(image, gamma=1.5, clip_limit=2.0, tile_grid_size=(8, 8))\n",
    "\n",
    "#     # グレースケール変換\n",
    "#     if preprocessed_image.ndim == 3:\n",
    "#         gray_image = cv2.cvtColor(preprocessed_image, cv2.COLOR_BGR2GRAY)\n",
    "#     else:\n",
    "#         gray_image = preprocessed_image\n",
    "\n",
    "#     # リサイズ\n",
    "#     resized_image = mi.resize_image(gray_image, max_length=max_length)\n",
    "#     if resized_image is None:\n",
    "#         return np.zeros(target_length)  # ゼロベクトルを返す\n",
    "\n",
    "#     # HOG特徴量を計算\n",
    "#     hog_features = mi.calculate_hog_features(resized_image)\n",
    "\n",
    "#     # 次元を揃える（ゼロパディングまたはクリッピング）\n",
    "#     if len(hog_features) < target_length:\n",
    "#         hog_features = np.pad(hog_features, (0, target_length - len(hog_features)), mode=\"constant\")\n",
    "#     elif len(hog_features) > target_length:\n",
    "#         hog_features = hog_features[:target_length]\n",
    "\n",
    "#     return hog_features\n",
    "\n",
    "# # 並列処理でHOG特徴量を計算\n",
    "# with ThreadPoolExecutor() as executor:\n",
    "#     print(\"Calculating HOG features...\")\n",
    "#     hog_results = list(tqdm(\n",
    "#         executor.map(lambda row: process_row_for_hog(row), df.to_dicts()),\n",
    "#         total=len(df)\n",
    "#     ))\n",
    "\n",
    "# # データフレームに列を追加\n",
    "# df = df.with_columns(pl.Series(\"hog_features\", hog_results))\n",
    "\n",
    "# # Noneが含まれているか確認\n",
    "# none_count = mi.count_none_in_column(df, \"hog_features\")\n",
    "# print(f\"None values in hog_features: {none_count}\")\n",
    "\n",
    "# # 次元が一致しているか確認\n",
    "# print(\"Checking dimensions of HOG features...\")\n",
    "# mi.check_dimensions(df, \"hog_features\")\n",
    "\n",
    "# # UMAPによる次元削減\n",
    "# print(\"Applying UMAP for dimensionality reduction...\")\n",
    "# hog_features_reduced = mi.umap_reduction(df[\"hog_features\"].to_list(), n_components=128)\n",
    "# df = df.with_columns(pl.Series(\"hog_features_umap\", hog_features_reduced.tolist()))\n",
    "\n",
    "# # Zスコア正規化\n",
    "# print(\"Normalizing HOG features (UMAP) using Z-score normalization...\")\n",
    "# hog_features_normalized = mi.normalize_zscore(df[\"hog_features_umap\"].to_list())\n",
    "# df = df.with_columns(pl.Series(\"hog_features_umap_std\", hog_features_normalized.tolist()))\n",
    "\n",
    "# # Noneが含まれているか確認\n",
    "# none_count_umap = mi.count_none_in_column(df, \"hog_features_umap_std\")\n",
    "# print(f\"None values in hog_features_umap_std: {none_count_umap}\")\n",
    "\n",
    "# # ゼロベクトルが含まれているか確認\n",
    "# zero_count_umap = mi.count_zeros_in_column(df, \"hog_features_umap_std\")\n",
    "# print(f\"Zero vectors in hog_features_umap_std: {zero_count_umap}\")\n",
    "\n",
    "# # 次元が一致しているか確認\n",
    "# mi.check_dimensions(df, \"hog_features_umap_std\")\n",
    "\n",
    "# # 結果を確認\n",
    "# print(df.head())\n",
    "\n",
    "# # 保存\n",
    "# output_parquet_path = \"./temp_with_hog_umap.parquet\"\n",
    "# df.write_parquet(output_parquet_path)\n",
    "# print(f\"Processed DataFrame saved to {output_parquet_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9f3352e-4854-4c4f-be27-5049326dad9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Zernike Moments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 14890/14890 [01:39<00:00, 150.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None values in zernike_features: 0\n",
      "Checking dimensions of Zernike features...\n",
      "Total rows in zernike_features: 14890\n",
      "Number of rows with dimension mismatch in zernike_features: 0\n",
      "Reducing Zernike features using UMAP...\n",
      "Normalizing Zernike features...\n",
      "None values in zernike_features_std: 0\n",
      "shape: (5, 35)\n",
      "┌───────┬─────────┬─────────────┬───────┬───┬─────────────┬─────────────┬─────────────┬────────────┐\n",
      "│ index ┆ dirname ┆ path        ┆ width ┆ … ┆ hog_feature ┆ zernike_fea ┆ zernike_fea ┆ zernike_fe │\n",
      "│ ---   ┆ ---     ┆ ---         ┆ ---   ┆   ┆ s_umap_std  ┆ tures       ┆ tures_umap  ┆ atures_std │\n",
      "│ i64   ┆ str     ┆ str         ┆ i64   ┆   ┆ ---         ┆ ---         ┆ ---         ┆ ---        │\n",
      "│       ┆         ┆             ┆       ┆   ┆ list[f64]   ┆ array[f64,  ┆ list[f64]   ┆ list[f64]  │\n",
      "│       ┆         ┆             ┆       ┆   ┆             ┆ 25]         ┆             ┆            │\n",
      "╞═══════╪═════════╪═════════════╪═══════╪═══╪═════════════╪═════════════╪═════════════╪════════════╡\n",
      "│ 0     ┆ 61      ┆ ../mydata/0 ┆ 3000  ┆ … ┆ [0.320735,  ┆ [0.31831,   ┆ [1.338274,  ┆ [-0.85549, │\n",
      "│       ┆         ┆ 0_working/2 ┆       ┆   ┆ 0.346905, … ┆ 0.113849, … ┆ 9.980234, … ┆ -0.774137, │\n",
      "│       ┆         ┆ 022-05-0…   ┆       ┆   ┆ 0.05526…    ┆ 0.043506…   ┆ 3.89326…    ┆ … -0.083…  │\n",
      "│ 1     ┆ 61      ┆ ../mydata/0 ┆ 3000  ┆ … ┆ [0.082011,  ┆ [0.31831,   ┆ [3.093058,  ┆ [1.157406, │\n",
      "│       ┆         ┆ 0_working/2 ┆       ┆   ┆ -0.117283,  ┆ 0.01185, …  ┆ 10.377309,  ┆ 0.132146,  │\n",
      "│       ┆         ┆ 022-05-0…   ┆       ┆   ┆ … 0.7670…   ┆ 0.054924]   ┆ … 3.9035…   ┆ … 0.10010… │\n",
      "│ 2     ┆ 61      ┆ ../mydata/0 ┆ 3000  ┆ … ┆ [0.304551,  ┆ [0.31831,   ┆ [1.964415,  ┆ [-0.13725, │\n",
      "│       ┆         ┆ 0_working/2 ┆       ┆   ┆ 0.243071, … ┆ 0.008934, … ┆ 9.249235, … ┆ -2.44257,  │\n",
      "│       ┆         ┆ 022-05-0…   ┆       ┆   ┆ 0.43992…    ┆ 0.03051]    ┆ 3.93777…    ┆ … 0.70766… │\n",
      "│ 3     ┆ 61      ┆ ../mydata/0 ┆ 3000  ┆ … ┆ [0.232149,  ┆ [0.31831,   ┆ [2.340459,  ┆ [0.294107, │\n",
      "│       ┆         ┆ 0_working/2 ┆       ┆   ┆ 0.142865, … ┆ 0.045414, … ┆ 10.349661,  ┆ 0.069042,  │\n",
      "│       ┆         ┆ 022-05-0…   ┆       ┆   ┆ -0.2122…    ┆ 0.056593…   ┆ … 3.9022…   ┆ … 0.07731… │\n",
      "│ 4     ┆ 61      ┆ ../mydata/0 ┆ 3000  ┆ … ┆ [0.228234,  ┆ [0.31831,   ┆ [2.16502,   ┆ [0.092863, │\n",
      "│       ┆         ┆ 0_working/2 ┆       ┆   ┆ 0.234845, … ┆ 0.061341, … ┆ 10.487244,  ┆ 0.383061,  │\n",
      "│       ┆         ┆ 022-05-0…   ┆       ┆   ┆ -0.7533…    ┆ 0.033273…   ┆ … 4.00802…  ┆ … 1.95584… │\n",
      "└───────┴─────────┴─────────────┴───────┴───┴─────────────┴─────────────┴─────────────┴────────────┘\n",
      "Processed DataFrame saved to ./temp_with_zernike.parquet\n"
     ]
    }
   ],
   "source": [
    "# データフレームを読み込む\n",
    "df = pl.read_parquet(\"./temp.parquet\")\n",
    "\n",
    "# Zernike Moments を計算する関数\n",
    "def process_row_for_zernike(row, radius=64, degree=8):\n",
    "    \"\"\"\n",
    "    各画像についてZernike Momentsを計算する。\n",
    "\n",
    "    Args:\n",
    "        row: データフレームの1行（辞書形式）。\n",
    "        radius: 半径のサイズ。\n",
    "        degree: 最大次数。\n",
    "\n",
    "    Returns:\n",
    "        Zernike Momentsのベクトル。\n",
    "    \"\"\"\n",
    "    # 画像を読み込む\n",
    "    image = mi.load_image(row[\"path\"], library=\"opencv\")\n",
    "    if image is None:\n",
    "        return None\n",
    "\n",
    "    # 画像を前処理\n",
    "    preprocessed_image = mi.preprocess_image(image, gamma=1.5, clip_limit=2.0, tile_grid_size=(8, 8))\n",
    "\n",
    "    # グレースケール変換\n",
    "    if preprocessed_image.ndim == 3:\n",
    "        gray_image = cv2.cvtColor(preprocessed_image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray_image = preprocessed_image\n",
    "\n",
    "    # Zernike Momentsを計算\n",
    "    zernike_moments = mi.calculate_zernike_moments(gray_image, radius=radius, degree=degree)\n",
    "    return zernike_moments\n",
    "\n",
    "# 並列処理でZernike Momentsを計算\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    print(\"Calculating Zernike Moments...\")\n",
    "    zernike_results = list(tqdm(\n",
    "        executor.map(lambda row: process_row_for_zernike(row), df.to_dicts()),\n",
    "        total=len(df)\n",
    "    ))\n",
    "\n",
    "# データフレームに列を追加\n",
    "df = df.with_columns(pl.Series(\"zernike_features\", zernike_results))\n",
    "\n",
    "# None が含まれているか確認\n",
    "none_count = mi.count_none_in_column(df, \"zernike_features\")\n",
    "print(f\"None values in zernike_features: {none_count}\")\n",
    "\n",
    "# 次元が一致しているか確認\n",
    "print(\"Checking dimensions of Zernike features...\")\n",
    "mi.check_dimensions(df, \"zernike_features\")\n",
    "\n",
    "# UMAP による次元削減\n",
    "print(\"Reducing Zernike features using UMAP...\")\n",
    "zernike_umap = mi.umap_reduction(df[\"zernike_features\"].to_list(), n_components=32)\n",
    "df = df.with_columns(pl.Series(\"zernike_features_umap\", zernike_umap.tolist()))\n",
    "\n",
    "# 正規化\n",
    "print(\"Normalizing Zernike features...\")\n",
    "zernike_normalized = mi.normalize_zscore(df[\"zernike_features_umap\"].to_list())\n",
    "df = df.with_columns(pl.Series(\"zernike_features_std\", zernike_normalized.tolist()))\n",
    "\n",
    "# None の有無を確認\n",
    "none_count_std = mi.count_none_in_column(df, \"zernike_features_std\")\n",
    "print(f\"None values in zernike_features_std: {none_count_std}\")\n",
    "\n",
    "# 結果を確認\n",
    "print(df.head())\n",
    "\n",
    "# 保存\n",
    "output_parquet_path = \"./temp_with_zernike.parquet\"\n",
    "df.write_parquet(output_parquet_path)\n",
    "print(f\"Processed DataFrame saved to {output_parquet_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bc5aa7-dbff-41a8-ad2d-10b111724817",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(ml_env)",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
